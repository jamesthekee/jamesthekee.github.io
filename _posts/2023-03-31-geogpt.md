---
layout: post
title:  "Quizzing ChatGPT on geography"
date:  2023-03-31 12:00:00 +0000
tags: geography chatgpt stats
published: false
---

# Geography NLP

*This post began out of a little investigation into some inconsequential capabilities of ChatGPT, however it remains complete, and I'm not too happy with my methods, but it remains too much effort to see to the end and I cannot leave it unpublished. With that in mind, please enjoy.*

**Summary:** In this post I investigated ChatGPT’s ability to recall the coordinates of a city, using a script to test it on about 800 cities using the OpenAI API. Against my expectations, I find ~~no evidence of a correlation between ChatGPT's coordinate recall accuracy and properties like population, tourism or my own biased opinion on prominence. ~~
With no significant findings my main takeaway is what I've learnt using the API.

## Where this began

ChatGPT has demonstrated very impressive capabilities, so one day I wanted to test some random abilities of it. And at that point my inner annoying geography-nerd challenged it do a duel and quizzed its geographical knowledge. From this I found that it could:

1. Accurately recall coordinates of a given city.
2. Calculate the great-circle distance between any two cities.
3. Calculate bearings between two cities
4. Fairly accurately fetch cities nearby a coordinate
5. Figure out the country a coordinate was in
6. **Couldn’t** calculate the distance or bearings between two coordinates. 

I thought abilities 2 and 6 being both true was interesting - it seems it could perform the underlying task of calculating distance but couldn't on arbitrary numerical data, I thought this was interesting grounds to investigate. Especially if ChatGPT has actually grokked how to calculate great-circle distances. I decided to begin by looking at the simplest task, recalling coordinates. This first post looks at what I investigated, is dedicated to that, any following posts will focus on investigating the other tasks. 

This capability is more boring to look into, but I had a reason to look into this: when I saw ChatGPT do any of these tasks I thought I observed variable amounts of error, and it seemed to correlate for cities I considered obscure. Perhaps investigating the simplest task will also give a measurement of what cities ChatGPT considers obscure, and perhaps a proxy measurement for geographical or linguistic biases in GPT3's training set.

*An example of how ChatGPT performed on coordinate recall from manual input:*

| City | Actual coordinates | Predicted |
| --- | --- | --- |
| Kolkata, India | 22.5726° N, 88.3639° E. | 22.5726, 88.3639 |
| Kaduna, Nigeria | 10.5264° N, 7.4388° E. | 10.5319° N, 7.4294° E |
| Shiyan, China | 32.6292° N, 110.7980° E. | 22.8389° N, 120.4646° E |

## My Approach

I used this city database from [Kaggle](https://www.kaggle.com/datasets/juanmah/world-cities), giving over 28,000 cities, each with their coordinates, population and other data. I filtered the cities down by population to include only those of populations of over 200,000, leaving us with 2,800 cities. Then I created a function that queries the OpenAI chat API using the GPT-3.5-turbo model; and without change to any model parameters. (This means it is using the default temperature of 1, and there is a random component to the output). The prompt I used, is given below:

> **System**: "You are a helpful assistant, give the coordinates of a city, when provided. Answer tersely, to 6 decimal places, in the format X°(N/S), Y°(E/W)."
> 
> **User**:"{city}"

This prompt was designed to:

1. Minimise number of tokens in the response, 
2. Get the coordinates in a *mostly* universal format rather than the possibility of -50.5°, 12.5° or 50.5°W, 12.5°N.
3. Coax ChatGPT to give a precise answer as possible

Sometime it will respond, asking for a disambiguation of which city, and I handle this by using the same prompt above, but also give the country. One might see issues with this, but I’ll discuss that here[1]. An example of ChatGPT's response is given below.

> Sorry, could you please provide more information on which Concord you are referring to? There are multiple cities/towns/villages with this name in different parts of the world.”
> 

Once I had it working I got it running on my database, I did some rather unsystematic sampling[2] that I don’t have the patience to completely iron out, though it works well enough. This sample contains around 800 cities, from all continents and is slightly skewed towards very populous nations (e.g. China). I only did a subset of the 2,800 cities as the API requests were slow, and I was only making one request at a time.     

### Calculating error

Once I obtained the coordinates given by ChatGPT, I calculated the error. For the error, I decided to use the great-circle distance between the given coordinates and the one from the Kaggle database, using kilometres as the units. Since this is using the haversine formula, I call this value haversine throughout the rest of this post.

## Findings

Before reading this the section, consider taking this time to make some predictions on my theories. Will, there by any an identifiable correlation? Will there be one between population and the haversine? 

The first graph I plotted was haversine distance against the population of the city.

<img class="img1" src="/assets/images/geogpt1/gw_chart_336034.png"/>

This revealed that many of ChatGPT's guesses were completely off. The greatest distance possible, which is half the circumference of the earth, is around 20,000km and we have several on this scale. I examined every data point with a haversine distance of over 1,000km and found nearly all where from ambiguous cases or some strange oddity, more detail here[5]. I removed these anomalies from the data and then got something that looks like this.

<img class="img1" src="/assets/images/geogpt1/gw_chart_293117.png"/>

There’s a lot of overlap, so let’s look at the log of haversine. I set the minimum distance to 0.1km to avoid the issue of taking the log of 0, and colour each dot according to the continent it belongs to.

<img class="img1" src="/assets/images/geogpt1/gw_chart_105548.png" />

First we see that a city doesn't require a large population to have a low haversine error, there are many smaller cities (200k) with near exact answers.  Counter-intuitive to my theory, the megacities Delhi, Jakarta, Tokyo have a haversine between 3km and 10km. I guess this is because of sprawl, and ambiguous city centres. For example if you google the coordinates of Tokyo you can find multiple different answers from many sources, so it is possible this discord is the explanation for why it is so high for Tokyo.

Examining the data in detail most prominent cities have near zero haversines, but not all those with zero haversines seem very prominent. At this point I would suggest that this haversine error, doesn't discernibly depend on population (it is possible it is a factor for cities less than 200k that I've ignored). Let’s just look at the other graphs.

Here’s a clear look at the overall distribution of the loghaversine. Because I used a logarithm on the haversine, bear in mind that the bins are not actually equally sized. 

<img class="img1" src="/assets/images/geogpt1/overall.png"/>

Splitting the data by capital cities, there's no apparent difference on the graph, but I think that's an evil of this flawed graph. Computing the numbers, capitals average 3km haversine and non capitals are 11km. I can’t really see any significant difference that isn’t attributable to the smaller number of capitals in the sample. 

<img class="img1" src="/assets/images/geogpt1/capitals.png"/>

Below are the plots grouped by each city’s continent, and the averages recorded into this table below. The order of the most accurate continents overall are quite surprising, especially North America being the highest. Though since this data is so complex it’s hard to even comment why any the order is like that.

<img class="img1" src="/assets/images/geogpt1/output3.png"/>

| Measure | Africa | Asia | Europe | North America | South America | Oceania |
| --- | --- | --- | --- | --- | --- | --- |
| haversine mean | 12.0121 | 13.7024 | 1.0218 | 12.6534 | 0.5034 | 6.6091 |
| count | 93 | 406 | 119 | 129 | 103 | 7 |

Now here’s the average haversine distance, plotted against population. And because there isn’t enough unclear graphs, I made it into two similar histograms with different sizes bins. Which both give a sense that the simple negative correlation I was expecting, is simply not there. There is probably a complex correlation with like an S curve, but I think that would require too much work to demonstrate.

<img class="img1" src="/assets/images/geogpt1/output6.png"/>

<img class="img1" src="/assets/images/geogpt1/output5.png"/>

The histograms for different continents it looks like this. 

<img class="img1" src="/assets/images/geogpt1/combined.png"/>

A geographical plot looks like this.

<img class="img1" src="/assets/images/geogpt1/curious_project.jpg"/>

And if we separate every data point into 5 different groups $$G_{-1}$$, $$G_0$$, … to $$G_3$$, each $$G_i$$ containing data points with a loghaversine, that is in the interval $$[i, i+1)$$    

<img style="width: 1400px;" src="/assets/images/geogpt1/gw_chart_1118.png"/>

Another correlation I speculated was that loghaversine might correlate with tourism. Using this Wikipedia [resource](https://en.wikipedia.org/wiki/List_of_cities_by_international_visitors), and mixing various tourist numbers for about 100 cities, plotting tourist numbers in (2018 or 2016 if they are missing) against loghaversine I get this. There is no visible correlation. Well I guess next project I’ll spend my time investigating something useful.

<img class="img1" src="/assets/images/geogpt1/Untitled.png"/>

With some quick dirty data collection I also collected a sample of a few American cities, sampled them 10 times and measured the variance in the lat-long coordinates given by ChatGPT. Besides some ambiguous cases, there was very little difference between North American cities and the other continents.

## Conclusions

The resultant data is a bit too complex to find clear correlations and conclusions. I think something more systematic, large-scale and work with multiple models would be needed to highlight some kind of indirect measure of the internet's bias to know a place. The most interesting observations are that North America has such a high average haversine, and South America doing the lowest. I reckon I suggest that ChatGPT heavily memorises from is Wikipedia[2], and this is why it performs broadly well, but this may cause some error since not all sources agree.

### Footnotes

[1] I didn’t want it to be given the country of the city, because that feels like your priming the model and not properly testing it.

[2] I only sample by doing a city once, I didn’t want to have to do it multiple times- though that would be more robust against random mistakes and then could measure the std. I did sampling by starting doing the top 376 populous cities (that didn’t fail during the request). This took me to the 523rd sample, meaning 147 somehow failed. Then since I had so much China sampled I blacklisted it, then starting from the 1000th most populous samples, got 484 samples by incrementing by either 4 or 5. So yeah kind of scuffed when you want a representative sample. A graph below sort of shows how I sampled.

<img class="img1" src="/assets/images/geogpt1/sampling.png"/>

[3] Out of the 31, 28 turned out to be ambiguous city names, mostly from ones that I assume were American (North and south) colonial settlements. Examples like York, London, Córdoba. Amusing examples were ChatGPT confusing La Florida, Chile for the entire state of Florida and Babylon, New York for the ancient city of Babylon. There were a few oddities with guessing Ganda, Angola as a location in the Atlantic sea and Bắc Ninh, Vietnam in the Indian Ocean. And the final one being a city called Nangandao, that ChatGPT thought was real and so did the database, but I can’t find a location for it.

[3] Additional oddities I've found, it confused Minamisatsuma for Minamisuita which is the first time I've seen different strings be confused.

[4] It seems plausible when you notice how well ChatGPT is at recalling information on obscure content that happens to be on Wikipedia. Observations like asking it about Babylon gives the coordinates of the ancient city rather than the town in New York. It can also easily recall well geolocational data of small English towns using the OS grid reference (A grid reference system in Britain). I've also seen it memorises postal codes and populations fairly accurately. 

## Addendum

### API usage

Overall I spent a total of $0.21 on API calls, from 1646 total text completion calls. Since I obtained 857 records, that means half of all calls resulted in a timeout or required a disambiguation. Using the pricing of $0.002/1k tokens means I must have used 105,000 tokens total and about 60 tokens a request. 

### What I learnt

- Familiarity with OpenAI API. I am more aware now that spending more than 5 minutes to reduce API costs is insane when dealing with such few API calls. So in the future I will be less hesitant to experiment and less afraid to fail. 
- Python has no inbuilt library to add a timeout for a function for windows, and it only exists for Linux. Which to me is completely insane.
- Pygwalker is kind of a cool library for exploring data, though it there seems like some ridiculous features that should be in by default. Like you can’t have a scatter plot with constant opacity for each data point without creating a column in your data frame with just a constant value to put into the graph’s opacity attribute.

### Suggested follow-work

- How does it compare to other models? (GPT2, GPT4, Claude, etc.)
- Can we fabricate city names, and get ChatGPT to answer? My few tries seem to be no, but maybe a good query could coax an answer out. I think China might be the best bet as ChatGPT gave answers for cities I could find little evidence for.
- China, Japan and maybe several other countries have their city names not represented in their native language, this could bias the data in some way. Perhaps if this is repeated this issue should be properly considered.
- Perhaps a map could be generated from a LLM's understand of the world.
